This is an overview of the multimodal projects from June 2021 to December 2021.

## Overall Plan

- Read at least ten papers
> Write summaries
>> - [ ] Paper1: Oscar: Object-Semantics Aligned Pre-training
for Vision-Language Tasks https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123750120.pdf


- Watch All the CMU's Multimodal Machine Learning course (11-777)
> Each lecture consists of 3 segments and **write one full long sentence for each segment**.

### Week 1 (Jun 19-Jun 25)
| Task           | Time required | Current Status | Finished | 
|----------------|---------------|----------------|-----------|
|  lecture  | 2 hours  |   in progress |  <ul><li>- [ ] 4.2</li><li>- [ ] 5.1</li></ul>
|  paper   | 2 hours  |  in progress | 


### lectures Notes
<details open>
  <summary>lectures</summary>
  <details>
    <summary>lecture 2</summary>
    <ol>
      <li></li>
      <li></li>
      <li></li>
    </ol>
  </details>
</details>

## Resource

### Awesome Reading
https://github.com/pliang279/awesome-multimodal-ml

### Course Link
CMU Multimodal Courses
```
[1] Main: https://cmu-multicomp-lab.github.io/mmml-course/fall2020/syllabus/#course-material
[2] Complementary: https://yonatanbisk.com/teaching/mmml-s21/
```
### Dataset
https://yonatanbisk.com/teaching/mmml-s21/#:~:text=from%20max%20grade.-,Datasets,-The%20course%20will

